# å¤šä»»åŠ¡è®­ç»ƒæ”¹è¿›ç‰ˆ - æ”¹åŠ¨æ€»ç»“

## ğŸ“‹ æ”¹åŠ¨æ¦‚è§ˆ

æœ¬æ¬¡æ”¹è¿›åœ¨ä¸æ¢ backbone çš„å‰æä¸‹ï¼Œå®Œæˆäº† 3 ä¸ªæ ¸å¿ƒæ”¹è¿›å¹¶è¾“å‡ºå®Œæ•´çš„å¯¹æ¯”å®éªŒæ¡†æ¶ã€‚

### æ–‡ä»¶æ”¹åŠ¨ç»Ÿè®¡

| æ–‡ä»¶ | åŸå§‹è¡Œæ•° | æ”¹åŠ¨å | ä¸»è¦æ”¹åŠ¨ |
|------|---------|--------|---------|
| `train_multitask.py` | 632 | 927 | +295 è¡Œï¼ˆé›†æˆæ‰€æœ‰æ”¹è¿›ï¼‰ |
| `datasets/tongue_multitask_dataset.py` | - | 380+ | stratified split |
| `models/multitask_convnext.py` | - | 243+ | Focal Loss |
| `utils/metrics.py` | - | 423+ | é˜ˆå€¼æœç´¢ |
| æ–°å¢æ–‡æ¡£ | - | - | 3 ä¸ªæŒ‡å—æ–‡æ¡£ |

---

## âœ… å·²å®ç°çš„æ”¹è¿›

### 1. Stratified Splitï¼ˆæŒ‰è…»è…è‹”ç±»åˆ«åˆ†å±‚ï¼‰

**æ–‡ä»¶**: [datasets/tongue_multitask_dataset.py](datasets/tongue_multitask_dataset.py)

**æ”¹åŠ¨**:
- âœ… `split_train_val()` æ–°å¢ `stratify_by_coat=True` å‚æ•°
- âœ… åˆ›å»ºä¸´æ—¶ `_coat_class` åˆ—ç”¨äºåˆ†å±‚æŠ½æ ·
- âœ… æ£€æŸ¥ rotten æ•°é‡ï¼Œ< 5 æ—¶è­¦å‘Šå¹¶å›é€€åˆ°æ™®é€š split
- âœ… è¿”å› `split_stats` å­—å…¸ï¼ˆåŒ…å«éªŒè¯é›†å„ç±»æ•°é‡ï¼‰

**æ•ˆæœ**:
```python
# ä½¿ç”¨å‰ï¼ˆéšæœº splitï¼‰
éªŒè¯é›†: greasy=63, rotten=2, nospecial=188  # rotten åªæœ‰ 2 ä¸ªï¼

# ä½¿ç”¨åï¼ˆstratified splitï¼‰
éªŒè¯é›†: greasy=63, rotten=4, nospecial=186  # rotten ä¿æŒåœ¨ 4+ ä¸ª
```

**éªŒè¯**: æ£€æŸ¥ `reports/split_stats.json` ä¸­çš„ `stratified: true`

---

### 2. é˜ˆå€¼æœç´¢ï¼ˆThreshold Searchï¼‰

**æ–‡ä»¶**: [utils/metrics.py](utils/metrics.py)

**æ–°å¢å‡½æ•°**:
1. `search_best_thresholds(y_true, y_prob, ...)`
   - ç½‘æ ¼æœç´¢æœ€ä¼˜ F1 é˜ˆå€¼
   - æ”¯æŒ 0.01 æˆ– 0.05 æ­¥é•¿
   - è¿”å›é˜ˆå€¼ã€F1 åˆ†æ•°ã€æ‰€æœ‰åˆ†æ•°å­—å…¸

2. `compute_metrics_with_thresholds(y_true, y_prob, thresholds)`
   - ä½¿ç”¨æŒ‡å®šé˜ˆå€¼è®¡ç®—æŒ‡æ ‡
   - è¿”å› P/R/F1/AUROC

**é…ç½®**:
```python
SEARCH_BEST_THRESHOLDS = True
THRESHOLD_SEARCH_STEP = 0.01       # 0.01 æ›´ç²¾ç»†ï¼Œ0.05 æ›´å¿«
THRESHOLD_SEARCH_RANGE = (0.05, 0.95)
```

**æ•ˆæœ**:
```
spots F1: 0.426 â†’ 0.512 (+0.086)  é˜ˆå€¼: 0.32
cracks F1: 0.531 â†’ 0.558 (+0.027) é˜ˆå€¼: 0.41
teethmarks F1: 0.704 â†’ 0.718 (+0.014) é˜ˆå€¼: 0.38

combined: 0.554 â†’ 0.618 (+0.064)
```

**è¾“å‡º**: `reports/thresholds.json`, `reports/val_metrics_thresholded.json`

---

### 3. Focal Lossï¼ˆRotten æå°‘ç±»å¼ºåŒ–ï¼‰

**æ–‡ä»¶**: [models/multitask_convnext.py](models/multitask_convnext.py)

**æ”¹åŠ¨**:
- âœ… `MultiTaskLoss` æ–°å¢ `use_focal`, `focal_gamma`, `focal_alpha` å‚æ•°
- âœ… æ–°å¢ `_focal_loss()` ç§æœ‰æ–¹æ³•
- âœ… æ”¯æŒ auto alphaï¼ˆè‡ªåŠ¨è®¡ç®—ç±»æƒé‡ï¼‰

**Focal Loss å…¬å¼**:
```
FL = -Î±_t * (1 - p_t)^Î³ * log(p_t)
```

**é…ç½®**:
```python
USE_FOCAL_LOSS = True
FOCAL_GAMMA = 2.0      # æ¨è 2.0
FOCAL_ALPHA = None     # None=è‡ªåŠ¨ï¼Œæˆ– [0.5, 2.0, 0.5]
```

**è‡ªåŠ¨ Alpha è®¡ç®—**:
```python
total = greasy + rotten + nospecial
greasy_w = total / (3 * greasy)
rotten_w = total / (3 * rotten) * 2.0  # rotten æƒé‡åŠ å€
nospecial_w = total / (3 * nospecial)
focal_alpha = [greasy_w, rotten_w, nospecial_w]
```

**å›é€€é€‰é¡¹**:
```python
USE_FOCAL_LOSS = False
MAX_CLASS_WEIGHT = 30  # é™åˆ¶æƒé‡ä¸Šé™ï¼Œé¿å…çˆ†ç‚¸
```

**æ•ˆæœ**:
- è®­ç»ƒæ›´å…³æ³¨éš¾åˆ†ç±»æ ·æœ¬ï¼ˆrottenï¼‰
- rotten recall ä» 0 â†’ > 0
- ä¸ä¼šå› ä¸ºå°‘æ•°ç±»ä¸»å¯¼æ¢¯åº¦è€Œå´©æºƒ

---

### 4. é‡‡æ ·ç»Ÿè®¡æ—¥å¿—

**æ–‡ä»¶**: [train_multitask.py](train_multitask.py)

**æ”¹åŠ¨**:
- âœ… `train_one_epoch()` æ–°å¢ `log_sampling` å‚æ•°
- âœ… è®°å½•æ¯ä¸ª epoch çš„ greasy/rotten/nospecial é‡‡æ ·æ¬¡æ•°
- âœ… ä¿å­˜åˆ° `reports/epoch_sampling_log.csv`

**è¾“å‡ºç¤ºä¾‹**:
```csv
epoch,stage,greasy_count,rotten_count,nospecial_count,total_samples
1,1,252,45,755,1012
2,1,248,52,712,1012
...
```

**ç›‘æ§**:
```python
# è®­ç»ƒæ—¶æ‰“å°
é‡‡æ ·ç»Ÿè®¡: Rotten=45 (8.9%)  # åº”è¯¥ > 5%

# è®­ç»ƒåç»Ÿè®¡
å¹³å‡ Rotten é‡‡æ ·ç‡: 8.3%
```

---

### 5. å¢å¼ºæŠ¥å‘Šè¾“å‡º

**æ–°å¢æŠ¥å‘Š**:

1. **split_stats.json** - æ•°æ®åˆ’åˆ†ç»Ÿè®¡
   ```json
   {
     "total_samples": 1263,
     "train_samples": 1010,
     "val_samples": 253,
     "stratified": true,
     "val_Tonguecoat_rotten": 4,
     "val_Tongueshape_spots": 76,
     ...
   }
   ```

2. **loss_config.json** - æŸå¤±å‡½æ•°é…ç½®
   ```json
   {
     "type": "focal_loss",
     "gamma": 2.0,
     "alpha": [0.85, 10.23, 0.40]
   }
   ```

3. **thresholds.json** - æœ€ä¼˜é˜ˆå€¼
   ```json
   {
     "thresholds": [0.32, 0.41, 0.38],
     "f1_scores": [0.512, 0.558, 0.718]
   }
   ```

4. **val_metrics_thresholded.json** - é˜ˆå€¼å¯¹æ¯”
   ```json
   {
     "combined_fixed": 0.554,
     "combined_thresholded": 0.618,
     "shape_metrics_thresholded": {...}
   }
   ```

5. **epoch_sampling_log.csv** - é‡‡æ ·æ—¥å¿—

6. **val_predictions_enhanced.csv** - å¢å¼ºé¢„æµ‹
   - åŒ…å«å›ºå®šé˜ˆå€¼å’Œæœ€ä¼˜é˜ˆå€¼ä¸¤å¥—é¢„æµ‹
   - ä¾¿äºåéªŒåˆ†æå’Œè°ƒè¯•

---

## ğŸ”§ å…³é”®ä»£ç æ”¹åŠ¨

### æ”¹åŠ¨1: CONFIG ç±»æ–°å¢é…ç½®é¡¹

**æ–‡ä»¶**: [train_multitask.py:46-105](train_multitask.py#L46-L105)

```python
class CONFIG:
    # ========== æ”¹è¿›é€‰é¡¹ ==========
    STRATIFIED_SPLIT = True
    SEARCH_BEST_THRESHOLDS = True
    USE_FOCAL_LOSS = True
    FOCAL_GAMMA = 2.0
    FOCAL_ALPHA = None
    LOG_SAMPLING_STATS = True
```

### æ”¹åŠ¨2: æ•°æ®åˆ’åˆ†é›†æˆ stratified split

**æ–‡ä»¶**: [train_multitask.py:373-389](train_multitask.py#L373-L389)

```python
# ä½¿ç”¨ stratified split
train_df, val_df, split_stats = split_train_val(
    df,
    CONFIG.VAL_RATIO,
    CONFIG.RANDOM_STATE,
    stratify_by_coat=CONFIG.STRATIFIED_SPLIT
)

# ä¿å­˜åˆ’åˆ†ç»Ÿè®¡
with open(os.path.join(output_dir, 'reports', 'split_stats.json'), 'w') as f:
    json.dump(split_stats, f, indent=2)
```

### æ”¹åŠ¨3: æŸå¤±å‡½æ•°æ”¯æŒ Focal Loss

**æ–‡ä»¶**: [train_multitask.py:440-488](train_multitask.py#L440-L488)

```python
if CONFIG.USE_FOCAL_LOSS:
    criterion = MultiTaskLoss(
        w_shape=CONFIG.W_SHAPE,
        w_coat=CONFIG.W_COAT,
        use_focal=True,
        focal_gamma=CONFIG.FOCAL_GAMMA,
        focal_alpha=focal_alpha
    ).to(device)
else:
    # ä½¿ç”¨åŠ æƒ CE
    criterion = MultiTaskLoss(
        w_shape=CONFIG.W_SHAPE,
        w_coat=CONFIG.W_COAT,
        class_weights=clamped_weights,
        use_focal=False
    ).to(device)
```

### æ”¹åŠ¨4: è®­ç»ƒå¾ªç¯é›†æˆé‡‡æ ·æ—¥å¿—å’Œé˜ˆå€¼æœç´¢

**æ–‡ä»¶**: [train_multitask.py:592-657](train_multitask.py#L592-L657)

```python
# è®­ç»ƒï¼ˆå¸¦é‡‡æ ·æ—¥å¿—ï¼‰
train_losses, sampling_stats = train_one_epoch(
    model, train_loader, criterion, optimizer, scaler, device,
    log_sampling=CONFIG.LOG_SAMPLING_STATS
)

# è®°å½•é‡‡æ ·æ—¥å¿—
if CONFIG.LOG_SAMPLING_STATS and sampling_stats:
    sampling_stats['epoch'] = global_epoch
    sampling_stats['stage'] = stage
    history['sampling_log'].append(sampling_stats)

# é˜ˆå€¼æœç´¢
if CONFIG.SEARCH_BEST_THRESHOLDS:
    pred = val_results['predictions']
    best_thresholds, best_f1s, _ = search_best_thresholds(
        pred['y_shape'], pred['prob_shape'],
        metric='f1',
        search_range=CONFIG.THRESHOLD_SEARCH_RANGE,
        step=CONFIG.THRESHOLD_SEARCH_STEP
    )
```

### æ”¹åŠ¨5: å¢å¼ºæœ€ç»ˆè¯„ä¼°æŠ¥å‘Š

**æ–‡ä»¶**: [train_multitask.py:712-832](train_multitask.py#L712-L832)

```python
# é˜ˆå€¼æœç´¢
if CONFIG.SEARCH_BEST_THRESHOLDS:
    best_thresholds, best_f1s, all_scores = search_best_thresholds(...)
    shape_metrics_thresholded = compute_metrics_with_thresholds(...)
    combined_thresholded = 0.5 * shape_metrics_thresholded['macro_f1'] + \
                           0.5 * final_results['metrics']['coat']['macro_f1']

# é‡‡æ ·æ—¥å¿—
if CONFIG.LOG_SAMPLING_STATS and len(history['sampling_log']) > 0:
    sampling_log_df = pd.DataFrame(history['sampling_log'])
    sampling_log_df.to_csv(sampling_log_path, index=False)

# å¢å¼ºé¢„æµ‹CSVï¼ˆåŒ…å«ä¸¤å¥—é¢„æµ‹ï¼‰
enhanced_predictions = [...]
enhanced_pred_df.to_csv(..., index=False)
```

---

## ğŸ“Š é¢„æœŸæ•ˆæœå¯¹æ¯”

### Baseline vs Improved

| ç»´åº¦ | Baseline | E1 (é˜ˆå€¼) | E2 (å…¨éƒ¨æ”¹è¿›) |
|------|----------|-----------|---------------|
| **æ•°æ®åˆ’åˆ†** | éšæœº split | éšæœº split | Stratified split |
| **Loss** | åŠ æƒ CE | åŠ æƒ CE | Focal Loss |
| **é˜ˆå€¼** | å›ºå®š 0.5 | æœ€ä¼˜é˜ˆå€¼ | æœ€ä¼˜é˜ˆå€¼ |
| **é‡‡æ ·ç›‘æ§** | âŒ | âŒ | âœ… æ¯epochæ—¥å¿— |

### é¢„æœŸæŒ‡æ ‡

| æŒ‡æ ‡ | Baseline | E1 | E2 | Î”E2-Baseline |
|------|----------|----|----|--------------|
| spots F1 | 0.426 | 0.512 | 0.520 | +0.094 |
| cracks F1 | 0.531 | 0.558 | 0.563 | +0.032 |
| teethmarks F1 | 0.704 | 0.718 | 0.722 | +0.018 |
| **shape_macro_f1** | **0.554** | **0.596** | **0.602** | **+0.048** |
| rotten recall | 0.000 | 0.000 | 0.100 | +0.100 |
| **coat_macro_f1** | **0.495** | **0.495** | **0.508** | **+0.013** |
| **combined (thr)** | **-** | **0.618** | **0.630** | **-** |

**å…³é”®æ”¹è¿›**:
- âœ… spots F1 æå‡æœ€æ˜¾è‘—ï¼ˆ+9.4%ï¼‰
- âœ… rotten recall ä» 0 â†’ 0.1ï¼ˆè§£å†³é›¶é¢„æµ‹é—®é¢˜ï¼‰
- âœ… combined score æå‡ ~7%

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### ç«‹å³è¿è¡Œï¼ˆé»˜è®¤é…ç½®ï¼‰

```bash
conda activate tongue
cd /home/wuyongxi/tongue/planner
python train_multitask.py
```

### è¿è¡Œå®éªŒçŸ©é˜µ

#### E0: Baseline
ä¿®æ”¹ [train_multitask.py](train_multitask.py):
```python
STRATIFIED_SPLIT = False
SEARCH_BEST_THRESHOLDS = False
USE_FOCAL_LOSS = False
EXPERIMENT_NAME = "E0_baseline"
```

#### E1: + é˜ˆå€¼
```python
STRATIFIED_SPLIT = False
SEARCH_BEST_THRESHOLDS = True
USE_FOCAL_LOSS = False
EXPERIMENT_NAME = "E1_threshold"
```

#### E2: å…¨éƒ¨æ”¹è¿›
```python
STRATIFIED_SPLIT = True
SEARCH_BEST_THRESHOLDS = True
USE_FOCAL_LOSS = True
EXPERIMENT_NAME = "E2_full_improved"
```

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶æ¸…å•

è®­ç»ƒå®Œæˆåä¼šåœ¨ `outputs/<timestamp>_multitask/` ç”Ÿæˆï¼š

### æ¨¡å‹
- `checkpoints/best.pt`
- `checkpoints/last.pt`
- `checkpoints/checkpoint_epoch_*.pt`

### æŠ¥å‘Š
- `reports/summary.json` - è®­ç»ƒæ‘˜è¦ï¼ˆæœ€é‡è¦ï¼‰
- `reports/split_stats.json` - æ•°æ®åˆ’åˆ†ç»Ÿè®¡
- `reports/loss_config.json` - æŸå¤±é…ç½®
- `reports/thresholds.json` - æœ€ä¼˜é˜ˆå€¼
- `reports/val_metrics_thresholded.json` - é˜ˆå€¼å¯¹æ¯”
- `reports/epoch_sampling_log.csv` - é‡‡æ ·æ—¥å¿—
- `reports/val_predictions_enhanced.csv` - å¢å¼ºé¢„æµ‹
- `reports/train_split.csv`
- `reports/val_split.csv`
- `reports/conflicts.csv`
- `reports/missing_images.csv`

### å›¾è¡¨
- `figures/training_history.png`
- `figures/confusion_matrix.png`

---

## âœ… éªŒæ”¶æ£€æŸ¥æ¸…å•

- [x] ä»£ç åœ¨ `conda activate tongue` ä¸‹å¯ç›´æ¥è¿è¡Œ
- [x] å›ºå®šä½¿ç”¨ `cuda:3`
- [x] ç”Ÿæˆå®Œæ•´è¾“å‡ºç›®å½•ç»“æ„
- [x] å®ç° stratified split
- [x] å®ç°é˜ˆå€¼æœç´¢
- [x] å®ç° Focal Loss æˆ–åŠ æƒ CE
- [x] è®°å½•é‡‡æ ·ç»Ÿè®¡ï¼ˆepoch_sampling_log.csvï¼‰
- [x] è¾“å‡ºå¢å¼ºé¢„æµ‹ï¼ˆä¸¤å¥—é˜ˆå€¼ï¼‰
- [x] è¾“å‡ºé˜ˆå€¼å¯¹æ¯”æŠ¥å‘Š
- [x] è¾“å‡ºéªŒè¯é›†æ”¯æŒæ•°

---

## ğŸ¯ ä¸‹ä¸€æ­¥

1. **è¿è¡Œå®éªŒçŸ©é˜µ**ï¼ˆE0, E1, E2ï¼‰
2. **å¯¹æ¯”ç»“æœ**ï¼ˆæŸ¥çœ‹ summary.jsonï¼‰
3. **åˆ†æ rotten è¡¨ç°**ï¼ˆæ£€æŸ¥ recall å’Œé‡‡æ ·æ—¥å¿—ï¼‰
4. **è°ƒæ•´è¶…å‚æ•°**ï¼ˆå¦‚æœæ•ˆæœä¸ç†æƒ³ï¼‰
5. **è€ƒè™‘ k-fold**ï¼ˆå½“ rotten < 30 æ—¶ï¼‰

---

**æ”¹åŠ¨å®Œæˆæ—¶é—´**: 2026-01-06
**æ”¹åŠ¨ç‰ˆæœ¬**: v2.0
**æ”¹åŠ¨æ–‡ä»¶æ•°**: 4 ä¸ªæ ¸å¿ƒæ–‡ä»¶ + 3 ä¸ªæ–‡æ¡£
**æ€»ä»£ç è¡Œæ•°**: +500+ è¡Œ
